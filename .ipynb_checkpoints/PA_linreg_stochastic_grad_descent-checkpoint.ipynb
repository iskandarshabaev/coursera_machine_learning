{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале напишем простую функцию для записи ответов в текстовый файл. Ответами будут числа, полученные в ходе решения этого задания, округленные до 3 знаков после запятой. Полученные файлы после выполнения задания надо отправить в форму на странице задания на Coursera.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, filename):\n",
    "    with open(filename, 'w') as f_out:\n",
    "        f_out.write(str(round(answer, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "adver_data.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TV       Radio   Newspaper       Sales\n",
       "count  200.000000  200.000000  200.000000  200.000000\n",
       "mean   147.042500   23.264000   30.554000   14.022500\n",
       "std     85.854236   14.846809   21.778621    5.217457\n",
       "min      0.700000    0.000000    0.300000    1.600000\n",
       "25%     74.375000    9.975000   12.750000   10.375000\n",
       "50%    149.750000   22.900000   25.750000   12.900000\n",
       "75%    218.825000   36.525000   45.100000   17.400000\n",
       "max    296.400000   49.600000  114.000000   27.000000"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "adver_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array(adver_data.values[:,0:3])\n",
    "y = np.array(adver_data.values[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 85.63933176  14.80964564  21.72410606]\n"
     ]
    }
   ],
   "source": [
    "means, stds = X.mean(axis = 0), X.std(axis = 0)\n",
    "print(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = (X - means) / stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ones = np.ones(len(X))\n",
    "X = np.hstack((X, np.ones((X.shape[0],1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    return np.mean((y_pred - y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Запишите ответ в файл '1.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.34575\n"
     ]
    }
   ],
   "source": [
    "answer1 = mserror(y, np.median(y))\n",
    "print(answer1)\n",
    "write_answer_to_file(answer1, '1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    return np.linalg.solve(np.dot(X.transpose(), X), np.dot(X.transpose(), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.91925365   2.79206274  -0.02253861  14.0225    ]\n"
     ]
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X, y)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Запишите ответ в файл '2.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0225\n"
     ]
    }
   ],
   "source": [
    "answer2 = np.sum([0., 0., 0., 1.] * norm_eq_weights)\n",
    "print(answer2)\n",
    "write_answer_to_file(answer2, '2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return np.dot(X, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения? Запишите ответ в файл '3.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78412631451\n"
     ]
    }
   ],
   "source": [
    "answer3 = mserror(y, linear_prediction(X, norm_eq_weights))\n",
    "print(answer3)\n",
    "write_answer_to_file(answer3, '3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    lin_pred = linear_prediction(X[train_ind], w)\n",
    "    error = mserror(y[train_ind], lin_pred)\n",
    "    #grad0 = \n",
    "    #grad1 = lin_pred[1]\n",
    "    #grad2 = lin_pred[2]\n",
    "    #grad3 = lin_pred[3]\n",
    "    return  w - 2 * eta/X.shape[0] * X[train_ind] * (lin_pred - y[train_ind])#np.array([grad0, grad1, grad2, grad3])\n",
    "    \n",
    "    #return w + 2 * eta/X.shape[0] * X[train_ind] * (y[train_ind] - linear_prediction(X[train_ind], w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - минимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        \n",
    "        next_w = stochastic_gradient_step(X, y, w, random_ind)\n",
    "        weight_dist = np.linalg.norm(w-next_w)\n",
    "        w = next_w\n",
    "        errors.append(mserror(y, linear_prediction(X, w)))\n",
    "        iter_num += 1\n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.99 s, sys: 47.8 ms, total: 6.04 s\n",
      "Wall time: 6.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X, y, np.zeros(X.shape[1]),max_iter=10**5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10ac0f0b8>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEPCAYAAACHuClZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10aaebac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10ac6fef0>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEPCAYAAACHuClZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109ca10f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.91069256e+00,   2.78209808e+00,  -8.10462217e-03,\n",
       "         1.40190566e+01])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7844125884067035"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Запишите ответ в файл '4.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78441258841\n"
     ]
    }
   ],
   "source": [
    "answer4 = mserror(y, linear_prediction(X, stoch_grad_desc_weights))\n",
    "print(answer4)\n",
    "write_answer_to_file(answer4, '4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответами к заданию будут текстовые файлы, полученные в ходе этого решения. Обратите внимание, что отправленные файлы не должны содержать пустую строку в конце. Данный нюанс является ограничением платформы Coursera. Мы работаем над исправлением этого ограничения.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
